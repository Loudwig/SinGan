{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchsummary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.functional import resize, to_tensor, to_pil_image\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os, datetime ,json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_from_minus1to1(t):\n",
    "    \"\"\"\n",
    "    Convertit un tenseur [-1,1] (CHW ou 1,C,H,W) en PIL Image.\n",
    "    \"\"\"\n",
    "    t = t.squeeze(0) if t.dim() == 4 else t          # B×C×H×W → C×H×W\n",
    "    t = ((t.clamp(-1, 1) + 1) / 2)                   # [-1,1] → [0,1]\n",
    "    return to_pil_image(t.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, patch_size, stride, debug=True):\n",
    "    # img: Tensor (C, H, W)\n",
    "    if debug:\n",
    "        print(f\"[extract_patches] input img shape: {img.shape}\")\n",
    "    img_batch = img.unsqueeze(0)  # (1, C, H, W)\n",
    "    patches = torch.nn.functional.unfold(img_batch, kernel_size=patch_size, stride=stride)\n",
    "    patches = patches.squeeze(0).T  # (num_patches, C*patch_size*patch_size)\n",
    "    if debug:\n",
    "        print(f\"[extract_patches] output patches shape: {patches.shape}\")\n",
    "        print(f\"[extract_patches] sample patch[0] min/max: {patches[0].min():.4f}/{patches[0].max():.4f}\")\n",
    "    return patches\n",
    "\n",
    "def get_gaussian_params(patches, debug=True):\n",
    "    # patches: Tensor (N, D)\n",
    "    if debug:\n",
    "        print(f\"[get_gaussian_params] patches shape: {patches.shape}\")\n",
    "    mu = patches.mean(dim=0)\n",
    "    centered = patches - mu\n",
    "    Sigma = (centered.T @ centered) / (patches.shape[0] - 1)\n",
    "    if debug:\n",
    "        print(f\"[get_gaussian_params] mu min/max: {mu.min():.4f}/{mu.max():.4f}\")\n",
    "        diff_sym = (Sigma - Sigma.T).abs().max()\n",
    "        print(f\"[get_gaussian_params] Sigma symmetry diff: {diff_sym:.4e}\")\n",
    "    return mu, Sigma\n",
    "\n",
    "import torch\n",
    "\n",
    "def matrix_sqrt_eig(mat, eps=1e-10, debug=True):\n",
    "    \"\"\"\n",
    "    Symmetric square root of an SPD matrix via eigen-decomposition.\n",
    "    \"\"\"\n",
    "    # 1) Enforce perfect symmetry\n",
    "    mat = (mat + mat.T) / 2\n",
    "    if debug:\n",
    "        print(\"  sym_diff in:\", (mat - mat.T).abs().max().item())\n",
    "\n",
    "    # 2) Eigen-decomposition\n",
    "    vals, vecs = torch.linalg.eigh(mat)\n",
    "    # 3) Clamp to avoid tiny negatives, then sqrt\n",
    "    vals = torch.clamp(vals, min=eps)\n",
    "    sqrt_mat = vecs @ torch.diag(torch.sqrt(vals)) @ vecs.T\n",
    "\n",
    "    # 4) Re-symmetrize result\n",
    "    sqrt_mat = (sqrt_mat + sqrt_mat.T) / 2\n",
    "    if debug:\n",
    "        print(\"  sym_diff out:\", (sqrt_mat - sqrt_mat.T).abs().max().item())\n",
    "\n",
    "    return sqrt_mat\n",
    "\n",
    "def wasserstein_2_gaussian_eig(mu1, Sigma1, mu2, Sigma2, eps=1e-12, debug=True):\n",
    "    \"\"\"\n",
    "    Computes W2^2 between two Gaussians (mu1, Sigma1) and (mu2, Sigma2),\n",
    "    using a robust eigen-based sqrt.\n",
    "    \"\"\"\n",
    "    # Mean term\n",
    "    diff_mu_sq = torch.norm(mu1 - mu2)**2\n",
    "    if debug:\n",
    "        print(\"||Δμ||² =\", diff_mu_sq.item())\n",
    "\n",
    "    # √Sigma1\n",
    "    A = Sigma1 + eps * torch.eye(Sigma1.size(0), device=Sigma1.device,dtype=torch.float64)\n",
    "    S1 = matrix_sqrt_eig(A, eps=eps, debug=debug)\n",
    "\n",
    "    # Inner product √(S1 Σ2 S1)\n",
    "    prod = S1 @ Sigma2 @ S1\n",
    "    if debug:\n",
    "        print(\"inner prod norm:\", prod.norm().item())\n",
    "    S2 = matrix_sqrt_eig(prod, eps=eps, debug=debug)\n",
    "\n",
    "    # Trace term\n",
    "    trace_term = torch.trace(Sigma1 + Sigma2 - 2 * S2)\n",
    "    if debug:\n",
    "        print(\"trace term =\", trace_term.item())\n",
    "\n",
    "    return diff_mu_sq + trace_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.n_hidden, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Last conv layer outputs 3 channels (RGB), no batchnorm or activation\n",
    "            nn.Conv2d(self.n_hidden, 3, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_name_to_path = {\n",
    "    \"oiseau\" : \"images/birds.png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 générateurs trouvés dans le checkpoint\n",
      "─── Description.txt ───\n",
      "date: 2025-05-30T16:14:07\n",
      "N: 8\n",
      "lambda_gp: 10\n",
      "r: 1.333\n",
      "lr: 0.0005\n",
      "betas: (0.5, 0.999)\n",
      "n_Discriminator: 5\n",
      "n_Generator: 2\n",
      "iter_per_scale: 2000\n",
      "alpha_rec: 10\n",
      "beta_sigma: 0.1\n",
      "comment: Sin Gan avec poids classique comme dans le papier sauf le padding\n",
      "────────────────────────\n",
      "\n",
      "sigma_n chargé (8 éléments) → 'loaded_sigma_n'\n",
      "z_star chargé de taille (1, 3, 21, 32) → 'loaded_z_star'\n",
      "8 générateurs instanciés → 'loaded_generators'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- (1) nom du modèle à charger -----------------------------------------------------\n",
    "image_name = \"oiseau\"\n",
    "model_name = \"basic\"\n",
    "model_dir  = os.path.join(\"models\",image_name ,model_name)\n",
    "weights_fp = os.path.join(model_dir, \"generators.pt\")\n",
    "descr_fp   = os.path.join(model_dir, \"Description.txt\")\n",
    "sigma_fp   = os.path.join(model_dir, \"sigma_n.json\")\n",
    "zstar_fp   = os.path.join(model_dir, \"z_star.pt\")  \n",
    "\n",
    "if not os.path.exists(weights_fp):\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier : {weights_fp}\")\n",
    "\n",
    "# --- (2) on lit la liste de state_dict ----------------------------------------------\n",
    "state_list = torch.load(weights_fp, map_location=\"cpu\")\n",
    "print(f\"{len(state_list)} générateurs trouvés dans le checkpoint\")\n",
    "\n",
    "# (facultatif) on affiche le petit fichier description\n",
    "if os.path.isfile(descr_fp):\n",
    "    print(\"─── Description.txt ───\")\n",
    "    with open(descr_fp, encoding=\"utf-8\") as f:\n",
    "        print(f.read().strip())\n",
    "    print(\"────────────────────────\\n\")\n",
    "\n",
    "# --- (2bis) on charge la liste sigma_n ----------------------------------------------\n",
    "if os.path.isfile(sigma_fp):\n",
    "    with open(sigma_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        loaded_sigma_n = json.load(f)\n",
    "    print(f\"sigma_n chargé ({len(loaded_sigma_n)} éléments) → 'loaded_sigma_n'\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier sigma_n : {sigma_fp}\")\n",
    "\n",
    "# --- (2ter) on charge z_star -------------------------------------------------------\n",
    "if os.path.isfile(zstar_fp):\n",
    "    loaded_z_star = torch.load(zstar_fp, map_location=\"cpu\")\n",
    "    print(f\"z_star chargé de taille {tuple(loaded_z_star.shape)} → 'loaded_z_star'\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier z_star : {zstar_fp}\")\n",
    "\n",
    "# --- (3) fonction helper : recrée un Generator adapté au state_dict -----------------\n",
    "def build_generator_from_state(sd, device=\"cpu\"):\n",
    "    for key in sd.keys():\n",
    "        if key.endswith(\".weight\") and sd[key].dim() == 4:\n",
    "            n_hidden = sd[key].shape[0]\n",
    "            break\n",
    "    else:\n",
    "        raise KeyError(\"Impossible d'inférer n_hidden depuis le state_dict.\")\n",
    "    G = Generator(n_hidden).to(device)\n",
    "    G.load_state_dict(sd, strict=True)\n",
    "    G.eval()\n",
    "    for p in G.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return G\n",
    "\n",
    "# --- (4) on construit la liste des générateurs chargés ------------------------------\n",
    "device = torch.device(\"cpu\")\n",
    "loaded_generators = [build_generator_from_state(sd, device=device) for sd in state_list]\n",
    "\n",
    "print(f\"{len(loaded_generators)} générateurs instanciés → 'loaded_generators'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams chargés → N=8, r=1.333\n"
     ]
    }
   ],
   "source": [
    "loaded_params = {}\n",
    "with open(descr_fp, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if \": \" not in line:\n",
    "            continue\n",
    "        key, val = line.strip().split(\": \", 1)\n",
    "        loaded_params[key] = val\n",
    "\n",
    "# Conversion au bon type\n",
    "loaded_N = int(loaded_params[\"N\"])\n",
    "loaded_r = float(loaded_params[\"r\"])  \n",
    "\n",
    "print(f\"Hyperparams chargés → N={loaded_N}, r={loaded_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2025-05-30T16:14:07',\n",
       " 'N': '8',\n",
       " 'lambda_gp': '10',\n",
       " 'r': '1.333',\n",
       " 'lr': '0.0005',\n",
       " 'betas': '(0.5, 0.999)',\n",
       " 'n_Discriminator': '5',\n",
       " 'n_Generator': '2',\n",
       " 'iter_per_scale': '2000',\n",
       " 'alpha_rec': '10',\n",
       " 'beta_sigma': '0.1',\n",
       " 'comment': 'Sin Gan avec poids classique comme dans le papier sauf le padding'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital tensor size : torch.Size([3, 164, 244])\n",
      "rescaled tensor size : torch.Size([3, 168, 249])\n"
     ]
    }
   ],
   "source": [
    "path = im_name_to_path[image_name]\n",
    "im = Image.open(path).convert(\"RGB\")\n",
    "im_tensor_cpu = to_tensor(im).to(device=\"cpu\")\n",
    "\n",
    "print(f\"inital tensor size : {im_tensor_cpu.shape}\")\n",
    "\n",
    "\n",
    "max_dim = 250\n",
    "_, H, W = im_tensor_cpu.shape\n",
    "scale_factor = max_dim / max(H, W)\n",
    "\n",
    "new_H = int(H * scale_factor)\n",
    "new_W = int(W * scale_factor)\n",
    "im_resized = resize(im_tensor_cpu.unsqueeze(0), size=[new_H, new_W], antialias=True).squeeze(0) *2 -1\n",
    "\n",
    "print(f\"rescaled tensor size : {im_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [im_resized.unsqueeze(0)]    # niveau 0 = fine\n",
    "\n",
    "for i in range(0, loaded_N):\n",
    "    prev = scales[-1]\n",
    "    _, _, h, w = prev.shape\n",
    "    new_h = max(int(h / loaded_r), 1)\n",
    "    new_w = max(int(w / loaded_r), 1)\n",
    "    down = resize(prev, size=[new_h, new_w], antialias=True)\n",
    "    scales.append(down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_multiscale(start_scale: int = loaded_N - 1,Generators = loaded_generators):\n",
    "    \"\"\"\n",
    "    start_scale = 0  → on ne renouvelle le bruit qu’à la fine scale\n",
    "    start_scale = N-1→ on renouvelle le bruit à toutes les échelles\n",
    "    \"\"\"\n",
    "    # Génération totale\n",
    "    if start_scale == loaded_N-1 : \n",
    "        h, w = scales[-1].shape[2:]\n",
    "        gen_image = [torch.zeros((1, 3, h, w), device=device)]\n",
    "\n",
    "         # 2. on remonte coarse → fine\n",
    "        for i in range(loaded_N):\n",
    "            k = loaded_N - 1 - i                    \n",
    "        \n",
    "            prev = gen_image[-1]\n",
    "            if prev.shape[2:] != scales[k].shape[2:]:\n",
    "                prev = F.interpolate(prev, size=scales[k].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "\n",
    "            z = torch.randn_like(prev) * loaded_sigma_n[k]\n",
    "            \n",
    "\n",
    "            x_k = Generators[k](z + prev) + prev\n",
    "            gen_image.append(x_k)\n",
    "\n",
    "        \n",
    "\n",
    "    else : \n",
    "        low = scales[start_scale+1] \n",
    "        up = F.interpolate(low, size=scales[start_scale].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "        gen_image = [up]\n",
    "\n",
    "         # 2. on remonte coarse → fine\n",
    "        for scale in range(start_scale,-1,-1):\n",
    "                            \n",
    "            prev = gen_image[-1]\n",
    "            if prev.shape[2:] != scales[scale].shape[2:]:\n",
    "                prev = F.interpolate(prev, size=scales[scale].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "\n",
    "            z = torch.randn_like(prev) * loaded_sigma_n[scale]\n",
    "            x_k = Generators[scale](z + prev) + prev\n",
    "            gen_image.append(x_k)\n",
    "\n",
    "    \n",
    "    return gen_image[1:]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake tensor shape: torch.Size([8, 3, 168, 249])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Génération et stockage des échantillons\n",
    "out_dir = \"outputs/\" + image_name\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "K = 8\n",
    "final_imgs = []\n",
    "\n",
    "for k in range(K):\n",
    "    imgs = generate_multiscale(start_scale=loaded_N-1, Generators=loaded_generators)\n",
    "    # On stocke la dernière image de chaque synthèse\n",
    "    final_imgs.append(imgs[-1].cpu().squeeze())\n",
    "\n",
    "# Convertir en [0,1] et assembler en un seul tenseur\n",
    "fake_tensor = torch.stack(final_imgs)               # (K, C, H, W)\n",
    "fake_tensor01 = (fake_tensor.clamp(-1, 1) + 1) / 2   # [-1,1] → [0,1]\n",
    "print(\"Fake tensor shape:\", fake_tensor01.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2452/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2325/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2476/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2418/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2500/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2498/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2589/1.0000\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2443/1.0000\n",
      "Fake patches shape: torch.Size([34992, 147])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Extract patches from fake images & print\n",
    "\n",
    "patch_size = 7\n",
    "stride = 3\n",
    "\n",
    "all_fake_patches = [extract_patches(img, patch_size, stride) for img in fake_tensor01]\n",
    "patches_fake = torch.cat(all_fake_patches, dim=0).double()\n",
    "\n",
    "print(\"Fake patches shape:\", patches_fake.shape)  # (total_fake_patches, C*patch_size^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real tensor shape: torch.Size([1, 3, 168, 249])\n",
      "Real image shape after squeeze: torch.Size([3, 168, 249])\n",
      "[extract_patches] input img shape: torch.Size([3, 168, 249])\n",
      "[extract_patches] output patches shape: torch.Size([4374, 147])\n",
      "[extract_patches] sample patch[0] min/max: 0.2902/1.0000\n",
      "Real patches shape: torch.Size([4374, 147])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Process real image & print shape\n",
    "\n",
    "# Suppose im_resized is your real image Tensor of shape (C, H, W)\n",
    "# If you have im_resized.unsqueeze(0), do:\n",
    "real_tensor = im_resized.unsqueeze(0)  # (1, C, H, W)\n",
    "print(\"Real tensor shape:\", real_tensor.shape)\n",
    "\n",
    "real_img = real_tensor.squeeze(0)      # (C, H, W)\n",
    "print(\"Real image shape after squeeze:\", real_img.shape)\n",
    "\n",
    "# Normalize real image to [0,1] just like your fakes\n",
    "real_img01 = (im_resized.clamp(-1, 1) + 1) / 2    # (C, H, W)\n",
    "\n",
    "patches_real = extract_patches(real_img01, patch_size, stride).double()\n",
    "print(\"Real patches shape:\", patches_real.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real image stats: 0.0 1.0 0.5860886573791504\n",
      "Fake image stats: 0.0 1.0 0.5844902992248535\n"
     ]
    }
   ],
   "source": [
    "print(\"Real image stats:\", real_img01.min().item(), real_img01.max().item(), real_img01.mean().item())\n",
    "print(\"Fake image stats:\", fake_tensor01.min().item(), fake_tensor01.max().item(), fake_tensor01.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_gaussian_params] patches shape: torch.Size([34992, 147])\n",
      "[get_gaussian_params] mu min/max: 0.2948/0.8676\n",
      "[get_gaussian_params] Sigma symmetry diff: 0.0000e+00\n",
      "[get_gaussian_params] patches shape: torch.Size([4374, 147])\n",
      "[get_gaussian_params] mu min/max: 0.3110/0.8628\n",
      "[get_gaussian_params] Sigma symmetry diff: 0.0000e+00\n",
      "||Δμ||² = 0.015375344281637589\n",
      "  sym_diff in: 0.0\n",
      "  sym_diff out: 0.0\n",
      "inner prod norm: 24.085508671834617\n",
      "  sym_diff in: 0.0\n",
      "  sym_diff out: 0.0\n",
      "trace term = 0.022162153927155773\n",
      "Wasserstein-2 Distance (squared): 0.0375\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compute Gaussian params & W2 distance\n",
    "\n",
    "mu_fake, Sigma_fake = get_gaussian_params(patches_fake)\n",
    "mu_real, Sigma_real = get_gaussian_params(patches_real)\n",
    "\n",
    "w2 = wasserstein_2_gaussian_eig(mu_real, Sigma_real, mu_fake, Sigma_fake)\n",
    "print(f\"Wasserstein-2 Distance (squared): {w2.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
