{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchsummary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.functional import resize, to_tensor, to_pil_image\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os, datetime ,json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_from_minus1to1(t):\n",
    "    \"\"\"\n",
    "    Convertit un tenseur [-1,1] (CHW ou 1,C,H,W) en PIL Image.\n",
    "    \"\"\"\n",
    "    t = t.squeeze(0) if t.dim() == 4 else t          # B×C×H×W → C×H×W\n",
    "    t = ((t.clamp(-1, 1) + 1) / 2)                   # [-1,1] → [0,1]\n",
    "    return to_pil_image(t.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, patch_size, stride):\n",
    "    \"\"\"\n",
    "    img: Tensor of shape (C, H, W)\n",
    "    returns: Tensor of shape (num_patches, C * patch_size * patch_size)\n",
    "    \"\"\"\n",
    "    img = img.unsqueeze(0)  # (1, C, H, W)\n",
    "    patches = torch.nn.functional.unfold(img, kernel_size=patch_size, stride=stride)\n",
    "    # patches: (1, C*patch_size*patch_size, num_patches)\n",
    "    patches = patches.squeeze(0).T\n",
    "    return patches\n",
    "\n",
    "# Helper: compute mean and covariance\n",
    "def get_gaussian_params(patches):\n",
    "    \"\"\"\n",
    "    patches: Tensor (N, D)\n",
    "    returns: mu (D,), Sigma (D, D)\n",
    "    \"\"\"\n",
    "    mu = patches.mean(dim=0)\n",
    "    centered = patches - mu\n",
    "    Sigma = (centered.T @ centered) / (patches.shape[0] - 1)\n",
    "    return mu, Sigma\n",
    "\n",
    "# Helper: matrix square root via SVD\n",
    "def matrix_sqrt(mat, eps=1e-6):\n",
    "    U, S, Vh = torch.linalg.svd(mat)\n",
    "    S_sqrt = torch.sqrt(S.clamp(min=eps))\n",
    "    return U @ torch.diag(S_sqrt) @ Vh\n",
    "\n",
    "# Wasserstein-2 between two Gaussians\n",
    "def wasserstein_2_gaussian(mu1, Sigma1, mu2, Sigma2, eps=1e-6):\n",
    "    diff_mu_sq = torch.norm(mu1 - mu2)**2\n",
    "    sqrt_Sigma1 = matrix_sqrt(Sigma1 + eps * torch.eye(Sigma1.shape[0], device=Sigma1.device))\n",
    "    product = sqrt_Sigma1 @ Sigma2 @ sqrt_Sigma1\n",
    "    sqrt_prod = matrix_sqrt(product, eps)\n",
    "    trace_term = torch.trace(Sigma1 + Sigma2 - 2 * sqrt_prod)\n",
    "    return diff_mu_sq + trace_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.n_hidden, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.n_hidden, self.n_hidden, 3, padding=1),\n",
    "            nn.BatchNorm2d(self.n_hidden),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # Last conv layer outputs 3 channels (RGB), no batchnorm or activation\n",
    "            nn.Conv2d(self.n_hidden, 3, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_name_to_path = {\n",
    "    \"oiseau\" : \"images/birds.png\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 générateurs trouvés dans le checkpoint\n",
      "─── Description.txt ───\n",
      "date: 2025-05-30T16:14:07\n",
      "N: 8\n",
      "lambda_gp: 10\n",
      "r: 1.333\n",
      "lr: 0.0005\n",
      "betas: (0.5, 0.999)\n",
      "n_Discriminator: 5\n",
      "n_Generator: 2\n",
      "iter_per_scale: 2000\n",
      "alpha_rec: 10\n",
      "beta_sigma: 0.1\n",
      "comment: Sin Gan avec poids classique comme dans le papier sauf le padding\n",
      "────────────────────────\n",
      "\n",
      "sigma_n chargé (8 éléments) → 'loaded_sigma_n'\n",
      "z_star chargé de taille (1, 3, 21, 32) → 'loaded_z_star'\n",
      "8 générateurs instanciés → 'loaded_generators'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- (1) nom du modèle à charger -----------------------------------------------------\n",
    "image_name = \"oiseau\"\n",
    "model_name = \"basic\"\n",
    "model_dir  = os.path.join(\"models\",image_name ,model_name)\n",
    "weights_fp = os.path.join(model_dir, \"generators.pt\")\n",
    "descr_fp   = os.path.join(model_dir, \"Description.txt\")\n",
    "sigma_fp   = os.path.join(model_dir, \"sigma_n.json\")\n",
    "zstar_fp   = os.path.join(model_dir, \"z_star.pt\")  \n",
    "\n",
    "if not os.path.exists(weights_fp):\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier : {weights_fp}\")\n",
    "\n",
    "# --- (2) on lit la liste de state_dict ----------------------------------------------\n",
    "state_list = torch.load(weights_fp, map_location=\"cpu\")\n",
    "print(f\"{len(state_list)} générateurs trouvés dans le checkpoint\")\n",
    "\n",
    "# (facultatif) on affiche le petit fichier description\n",
    "if os.path.isfile(descr_fp):\n",
    "    print(\"─── Description.txt ───\")\n",
    "    with open(descr_fp, encoding=\"utf-8\") as f:\n",
    "        print(f.read().strip())\n",
    "    print(\"────────────────────────\\n\")\n",
    "\n",
    "# --- (2bis) on charge la liste sigma_n ----------------------------------------------\n",
    "if os.path.isfile(sigma_fp):\n",
    "    with open(sigma_fp, \"r\", encoding=\"utf-8\") as f:\n",
    "        loaded_sigma_n = json.load(f)\n",
    "    print(f\"sigma_n chargé ({len(loaded_sigma_n)} éléments) → 'loaded_sigma_n'\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier sigma_n : {sigma_fp}\")\n",
    "\n",
    "# --- (2ter) on charge z_star -------------------------------------------------------\n",
    "if os.path.isfile(zstar_fp):\n",
    "    loaded_z_star = torch.load(zstar_fp, map_location=\"cpu\")\n",
    "    print(f\"z_star chargé de taille {tuple(loaded_z_star.shape)} → 'loaded_z_star'\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Impossible de trouver le fichier z_star : {zstar_fp}\")\n",
    "\n",
    "# --- (3) fonction helper : recrée un Generator adapté au state_dict -----------------\n",
    "def build_generator_from_state(sd, device=\"cpu\"):\n",
    "    for key in sd.keys():\n",
    "        if key.endswith(\".weight\") and sd[key].dim() == 4:\n",
    "            n_hidden = sd[key].shape[0]\n",
    "            break\n",
    "    else:\n",
    "        raise KeyError(\"Impossible d'inférer n_hidden depuis le state_dict.\")\n",
    "    G = Generator(n_hidden).to(device)\n",
    "    G.load_state_dict(sd, strict=True)\n",
    "    G.eval()\n",
    "    for p in G.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return G\n",
    "\n",
    "# --- (4) on construit la liste des générateurs chargés ------------------------------\n",
    "device = torch.device(\"cpu\")\n",
    "loaded_generators = [build_generator_from_state(sd, device=device) for sd in state_list]\n",
    "\n",
    "print(f\"{len(loaded_generators)} générateurs instanciés → 'loaded_generators'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams chargés → N=8, r=1.333\n"
     ]
    }
   ],
   "source": [
    "loaded_params = {}\n",
    "with open(descr_fp, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if \": \" not in line:\n",
    "            continue\n",
    "        key, val = line.strip().split(\": \", 1)\n",
    "        loaded_params[key] = val\n",
    "\n",
    "# Conversion au bon type\n",
    "loaded_N = int(loaded_params[\"N\"])\n",
    "loaded_r = float(loaded_params[\"r\"])  \n",
    "\n",
    "print(f\"Hyperparams chargés → N={loaded_N}, r={loaded_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2025-05-30T16:14:07',\n",
       " 'N': '8',\n",
       " 'lambda_gp': '10',\n",
       " 'r': '1.333',\n",
       " 'lr': '0.0005',\n",
       " 'betas': '(0.5, 0.999)',\n",
       " 'n_Discriminator': '5',\n",
       " 'n_Generator': '2',\n",
       " 'iter_per_scale': '2000',\n",
       " 'alpha_rec': '10',\n",
       " 'beta_sigma': '0.1',\n",
       " 'comment': 'Sin Gan avec poids classique comme dans le papier sauf le padding'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital tensor size : torch.Size([3, 164, 244])\n",
      "rescaled tensor size : torch.Size([3, 168, 249])\n"
     ]
    }
   ],
   "source": [
    "path = im_name_to_path[image_name]\n",
    "im = Image.open(path).convert(\"RGB\")\n",
    "im_tensor_cpu = to_tensor(im).to(device=\"cpu\")\n",
    "\n",
    "print(f\"inital tensor size : {im_tensor_cpu.shape}\")\n",
    "\n",
    "\n",
    "max_dim = 250\n",
    "_, H, W = im_tensor_cpu.shape\n",
    "scale_factor = max_dim / max(H, W)\n",
    "\n",
    "new_H = int(H * scale_factor)\n",
    "new_W = int(W * scale_factor)\n",
    "im_resized = resize(im_tensor_cpu.unsqueeze(0), size=[new_H, new_W], antialias=True).squeeze(0) *2 -1\n",
    "\n",
    "print(f\"rescaled tensor size : {im_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [im_resized.unsqueeze(0)]    # niveau 0 = fine\n",
    "\n",
    "for i in range(0, loaded_N):\n",
    "    prev = scales[-1]\n",
    "    _, _, h, w = prev.shape\n",
    "    new_h = max(int(h / loaded_r), 1)\n",
    "    new_w = max(int(w / loaded_r), 1)\n",
    "    down = resize(prev, size=[new_h, new_w], antialias=True)\n",
    "    scales.append(down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_multiscale(start_scale: int = loaded_N - 1,Generators = loaded_generators):\n",
    "    \"\"\"\n",
    "    start_scale = 0  → on ne renouvelle le bruit qu’à la fine scale\n",
    "    start_scale = N-1→ on renouvelle le bruit à toutes les échelles\n",
    "    \"\"\"\n",
    "    # Génération totale\n",
    "    if start_scale == loaded_N-1 : \n",
    "        h, w = scales[-1].shape[2:]\n",
    "        gen_image = [torch.zeros((1, 3, h, w), device=device)]\n",
    "\n",
    "         # 2. on remonte coarse → fine\n",
    "        for i in range(loaded_N):\n",
    "            k = loaded_N - 1 - i                    \n",
    "        \n",
    "            prev = gen_image[-1]\n",
    "            if prev.shape[2:] != scales[k].shape[2:]:\n",
    "                prev = F.interpolate(prev, size=scales[k].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "\n",
    "            z = torch.randn_like(prev) * loaded_sigma_n[k]\n",
    "            \n",
    "\n",
    "            x_k = Generators[k](z + prev) + prev\n",
    "            gen_image.append(x_k)\n",
    "\n",
    "        \n",
    "\n",
    "    else : \n",
    "        low = scales[start_scale+1] \n",
    "        up = F.interpolate(low, size=scales[start_scale].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "        gen_image = [up]\n",
    "\n",
    "         # 2. on remonte coarse → fine\n",
    "        for scale in range(start_scale,-1,-1):\n",
    "                            \n",
    "            prev = gen_image[-1]\n",
    "            if prev.shape[2:] != scales[scale].shape[2:]:\n",
    "                prev = F.interpolate(prev, size=scales[scale].shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "\n",
    "            z = torch.randn_like(prev) * loaded_sigma_n[scale]\n",
    "            x_k = Generators[scale](z + prev) + prev\n",
    "            gen_image.append(x_k)\n",
    "\n",
    "    \n",
    "    return gen_image[1:]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake tensor shape: torch.Size([8, 3, 168, 249])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Génération et stockage des échantillons\n",
    "out_dir = \"outputs/\" + image_name\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "K = 8\n",
    "final_imgs = []\n",
    "\n",
    "for k in range(K):\n",
    "    imgs = generate_multiscale(start_scale=loaded_N-1, Generators=loaded_generators)\n",
    "    # On stocke la dernière image de chaque synthèse\n",
    "    final_imgs.append(imgs[-1].cpu().squeeze())\n",
    "\n",
    "# Convertir en [0,1] et assembler en un seul tenseur\n",
    "fake_tensor = torch.stack(final_imgs)               # (K, C, H, W)\n",
    "fake_tensor01 = (fake_tensor.clamp(-1, 1) + 1) / 2   # [-1,1] → [0,1]\n",
    "print(\"Fake tensor shape:\", fake_tensor01.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake patches shape: torch.Size([9856, 2700])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Extract patches from fake images & print\n",
    "\n",
    "patch_size = 30\n",
    "stride = 5\n",
    "\n",
    "all_fake_patches = [extract_patches(img, patch_size, stride) for img in fake_tensor01]\n",
    "patches_fake = torch.cat(all_fake_patches, dim=0)\n",
    "\n",
    "print(\"Fake patches shape:\", patches_fake.shape)  # (total_fake_patches, C*patch_size^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real tensor shape: torch.Size([1, 3, 168, 249])\n",
      "Real image shape after squeeze: torch.Size([3, 168, 249])\n",
      "Real patches shape: torch.Size([1232, 2700])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Process real image & print shape\n",
    "\n",
    "# Suppose im_resized is your real image Tensor of shape (C, H, W)\n",
    "# If you have im_resized.unsqueeze(0), do:\n",
    "real_tensor = im_resized.unsqueeze(0)  # (1, C, H, W)\n",
    "print(\"Real tensor shape:\", real_tensor.shape)\n",
    "\n",
    "real_img = real_tensor.squeeze(0)      # (C, H, W)\n",
    "print(\"Real image shape after squeeze:\", real_img.shape)\n",
    "\n",
    "# Normalize real image to [0,1] just like your fakes\n",
    "real_img01 = (im_resized.clamp(-1, 1) + 1) / 2    # (C, H, W)\n",
    "\n",
    "patches_real = extract_patches(real_img01, patch_size, stride)\n",
    "print(\"Real patches shape:\", patches_real.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real image stats: 0.0 1.0 0.5860886573791504\n",
      "Fake image stats: 0.0 1.0 0.5840590596199036\n"
     ]
    }
   ],
   "source": [
    "print(\"Real image stats:\", real_img01.min().item(), real_img01.max().item(), real_img01.mean().item())\n",
    "print(\"Fake image stats:\", fake_tensor01.min().item(), fake_tensor01.max().item(), fake_tensor01.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein-2 Distance (squared): 2.4047\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compute Gaussian params & W2 distance\n",
    "\n",
    "mu_fake, Sigma_fake = get_gaussian_params(patches_fake)\n",
    "mu_real, Sigma_real = get_gaussian_params(patches_real)\n",
    "\n",
    "w2 = wasserstein_2_gaussian(mu_real, Sigma_real, mu_fake, Sigma_fake)\n",
    "print(f\"Wasserstein-2 Distance (squared): {w2.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
